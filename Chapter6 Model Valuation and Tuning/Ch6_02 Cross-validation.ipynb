{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'M']\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 유방암 데이터 정리 \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../dataset/wdbc.data', header = None)\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "\n",
    "# 클래스 레이블 문자열을 정수로 변환\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "print(le.transform(['M', 'B']))\n",
    "\n",
    "# 데이터 쪼개기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, stratify = y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 파이프라인으로 변환기와 추정기 연결하기 \"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(), PCA(n_components = 2),\n",
    "                       LogisticRegression(solver = 'liblinear', random_state = 1))\n",
    "# make_pipeline arg에 표준화를 위한 StandardScaler, 차원 축소를 위한 PCA\n",
    "# 그리고 훈련 모델인 LogisticRegression이 들어갔다.\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드 :  1, 클래스 분포 : [256 153], 정확도 : 0.935\n",
      "폴드 :  2, 클래스 분포 : [256 153], 정확도 : 0.935\n",
      "폴드 :  3, 클래스 분포 : [256 153], 정확도 : 0.957\n",
      "폴드 :  4, 클래스 분포 : [256 153], 정확도 : 0.957\n",
      "폴드 :  5, 클래스 분포 : [256 153], 정확도 : 0.935\n",
      "폴드 :  6, 클래스 분포 : [257 153], 정확도 : 0.956\n",
      "폴드 :  7, 클래스 분포 : [257 153], 정확도 : 0.978\n",
      "폴드 :  8, 클래스 분포 : [257 153], 정확도 : 0.933\n",
      "폴드 :  9, 클래스 분포 : [257 153], 정확도 : 0.956\n",
      "폴드 : 10, 클래스 분포 : [257 153], 정확도 : 0.956\n"
     ]
    }
   ],
   "source": [
    "\"\"\" k-겹 교차 검증 만들어보기 \"\"\"\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10).split(X_train, y_train)\n",
    "# kfold = StratifiedKFold(n_splits = 10, random_state = 1).split(X_train, y_train)\n",
    "# FutureWarning에 의해 Shuffle을 True로 설정하면 정확도가 내려가게 되고,\n",
    "# 예제대로 하면 shuffle을 False로 둬야한다.\n",
    "# 단, 그러면 random_state를 줄 필요가 없다.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold) :\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('폴드 : %2d, 클래스 분포 : %s, 정확도 : %.3f' % (k+1, np.bincount(y_train[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 정확도 점수 : [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556\n",
      " 0.97777778 0.93333333 0.95555556 0.95555556]\n",
      "CV 정확도 : 0.950 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 사이킷런의 k-겹 교차 검증 \"\"\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator = pipe_lr, X = X_train, y = y_train,\n",
    "                        cv = 10, n_jobs = 1)\n",
    "#n_jobs는 멀티코어\n",
    "\n",
    "print('CV 정확도 점수 : %s' % scores)\n",
    "print('CV 정확도 : %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 정확도 점수 : [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556\n",
      " 0.97777778 0.93333333 0.95555556 0.95555556]\n",
      "CV 정확도 : 0.950 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 여러 측정 지표를 사용하는 cross_validate \"\"\"\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores2 = cross_validate(estimator = pipe_lr, X = X_train, y = y_train,\n",
    "                        scoring = ['accuracy'], cv = 10, n_jobs = 1,\n",
    "                        return_train_score = False)\n",
    "print('CV 정확도 점수 : %s' % scores2['test_accuracy'])\n",
    "print('CV 정확도 : %.3f +/- %.3f' % (np.mean(scores2['test_accuracy']), np.std(scores2['test_accuracy'])))\n",
    "\n",
    "# 교차 검증에서 일반화 성능의 분산을 추정하는 자세한 방법은 책의 범위를 넘어섬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
